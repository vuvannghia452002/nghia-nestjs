1
00:00:01,050 --> 00:00:12,670
Distributed tracing is a technique used in the context of microservices architecture who monitor and analyze the flow of requests as they traverse multiple services in a distributed system.

2
00:00:13,410 --> 00:00:23,440
Understanding the interactions between services is crucial for diagnosing performance issues understanding system behavior and optimizing overall system performance.

3
00:00:23,730 --> 00:00:32,320
When a single user request this processed. It often involves multiple interconnected microservices working together to fulfill that request.

4
00:00:32,940 --> 00:00:46,120
Distributed tracing helps track the journey of a request through the services allowing developers and operations teams to gain valuable insights into how the services collaborate and identify potential bottlenecks or errors.

5
00:00:46,590 --> 00:00:54,430
This is particularly useful in complex systems were a single request can trigger a cascade of events that spanned multiple services.

6
00:00:55,350 --> 00:01:04,570
To implement distributed tracing in our system we usually assigned a unique identifier to each request and propagated through the system as the request is processed.

7
00:01:05,040 --> 00:01:18,310
As identifier is called a trace ID. Since trace ID is going to be passed along with the request it can be used to correlate all the logs and events generated by the services involved in processing that request.

8
00:01:19,260 --> 00:01:29,723
We can then use tracing systems to visualize the entire trace understanding the latency between services identify bottlenecks detect errors and optimize performance.

9
00:01:30,390 --> 00:01:38,080
In this lesson will focus on how to automatically generate trace ids and propagate them through the system in our nest js applications.

10
00:01:38,340 --> 00:01:53,230
To begin. Let's create a new library called tracing using the nest see ally. Let's open the newly generated tracing service file and add the following code.

11
00:01:55,230 --> 00:02:02,670
This method simply generates a random you you ID that will use as our trace ID. We need to a sinus ID only once.

12
00:02:03,120 --> 00:02:19,300
When the http request hits the application or when a cron job is trigger. Once we have the trace ID we need to propagate it through the system so that it can be used to court late all the logs in events generated by the services involved in processing of this request.

13
00:02:19,620 --> 00:02:34,560
In this lesson will focus on adding tracing to are alarmed generator events processing pipeline. So let's head over to the alarms generator service file and update the generate alarm method to generate a trace ID using our new tracing service.

14
00:02:35,010 --> 00:03:13,600
In the tattered to the message headers under the trace ID key. Note that to construct the headers object we use the nats headers function as we're using nats in our system but if your system was using something aside from nats you'd want to use the equivalent functionality there.

15
00:03:13,950 --> 00:03:22,270
Now to make the tracing service available any alarms generator module. We simply need to import the tracing module so let's go ahead and do that now.

16
00:03:22,950 --> 00:03:36,400
Aunt perfect. But all this and place we cannot switch our focus to the alarms service. Our goal now is to make sure that the trace ID is propagated through the system when the alarm service processes the message.

17
00:03:36,840 --> 00:03:50,190
Also let's make sure to automatically right the trace ID to the log messages so let's create a new terrain sing lager class that extends the default console lager class and overrides the format context method for us.

18
00:03:50,820 --> 00:03:58,300
To achieve this. Let's create a new file in the tracing library called tracing dot lager dot t s and add the following code.

19
00:03:59,760 --> 00:04:11,640
And let's breakfast class down. First we need to inject the request context and enquirer objects. The request context object represents the execution context of the incoming request.

20
00:04:12,000 --> 00:04:21,490
Which will used to extract the trace ID from. Here we assume that the logger will be used only by services that use the nats transport.

21
00:04:22,350 --> 00:04:29,130
The enquirer object contains the host object which will used to extract the name of the class that using the logger.

22
00:04:29,550 --> 00:04:36,880
So for example if we use the logger in the alarm service the enquirer object will contain the alarms service instance.

23
00:04:38,010 --> 00:04:45,040
And likewise if we inject the logger into the alarms controller the enquirer object will contain the alarms controller instance.

24
00:04:45,270 --> 00:04:55,470
This means that are lager provider will not only be request scoped but also transient scoped. Which means that a new instance of the logger will be created for each class that uses it.

25
00:04:56,100 --> 00:05:04,630
Now onto the format contexts the method. Here we need to extract the trace ID from the request context independent to the log message.

26
00:05:05,280 --> 00:05:13,930
Finally we need to register the tracing lager as a provider in the tracing module so let's open up the tracing module t s file and add the following code.

27
00:05:18,360 --> 00:05:27,490
Excellent. With this and place let's navigate to our alarm service and update the alarms module file to import the tracing module.

28
00:05:33,960 --> 00:05:42,880
Next let's head of to the alarms service controller file and updated to inject the tracing lager. Replacing the existing local lager instance.

29
00:05:47,490 --> 00:06:04,620
Let's save our changes head over to the terminal and start everything up with docker compose up. Once the application is up and running.

30
00:06:05,010 --> 00:06:23,380
Let's wait a little bit and observe the locks. As we can see all logs in the alarm service controller contain a trace idina great.

31
00:06:23,640 --> 00:06:31,960
However our trace ID is not yet propagated to the alarms classifier and notification services let's go ahead and fixed us now.

32
00:06:32,310 --> 00:06:40,440
For this will create a new client proxy class that internally updates the message headers with the trace ID before publishing a message.

33
00:06:40,890 --> 00:06:50,830
So as generate a new module first called nats dash client. And let's make sure to select the tracing library as the modules destination.

34
00:06:54,690 --> 00:07:12,010
Next inside of this module let's create a new file called constance with the following content. This file simply exports a constant that will represent the nats client provider.

35
00:07:12,900 --> 00:07:19,210
Next let's create yet another file and call it nats dash client dot proxy with the following content.

36
00:07:21,210 --> 00:07:29,681
As we can see where injecting the client proxy instance which represents our message broker and the context object into the constructor.

37
00:07:30,750 --> 00:07:40,270
We'll use the client proxy to publish messages to the message broker and the context object to access the trace ID that we attached to the message earlier.

38
00:07:40,650 --> 00:07:49,780
Also been nats client proxy class marked as request scoped which means that a new instance of this class will be created for each incoming request.

39
00:07:50,100 --> 00:07:56,380
This is important current because we want to make sure that each request has its own instance of the nats client proxy class.

40
00:07:57,240 --> 00:08:05,230
Next up let's add a new method called set trace ID that will be responsible for updating the message headers with the trace ID.

41
00:08:09,570 --> 00:08:19,960
Here we're checking if the message is an instance of nats record or know. If it is. Recruiting a new instance of the nats record build their class and updating its headers with the trace ID.

42
00:08:20,340 --> 00:08:27,160
Otherwise we're creating a new instance of the nats record build their class and updating its data and headers with the to trace ID.

43
00:08:28,410 --> 00:08:44,350
Finally let's add a new methods called cent and emit to mimic the client proxy a PR. Last but not least let's open up the nats client module file and register this nats client proxy as a provider and make sure to export.

44
00:08:45,780 --> 00:08:52,330
Also let's not forget to import the client module here with the exact same configuration we have in other applications.

45
00:09:01,770 --> 00:09:10,001
Great but this in place let's switch back to our alarm service and update the alarm service module file to import the nats client module.

46
00:09:10,230 --> 00:09:25,841
You can also remove the nats configuration from the clients module array. Last but not least let's update the alarm service controller file to inject the nats client proxy instead of just client proxy.

47
00:09:33,990 --> 00:09:42,690
Just before we test everything out let's also update the alarms classifier service to use the tracing lager instead of the local lager instance so.

48
00:09:43,050 --> 00:09:57,857
As open up our alarms classifier service module file and import the tracing module there. Next let's open up the alarms classifier service controller file and replaced the local lager instance with our new tracing lager.

49
00:10:02,490 --> 00:10:18,038
Let's save our changes. Head over to the terminal and take a look at those logs. As we can see the trace ID is now propagated to the alarms class of our services well fantastic.

50
00:10:18,748 --> 00:10:33,968
The last missing piece is the notification service. However it uses rabbit mq instead of nats so we would have to create a new rabbit client proxy class that would be similar to the nats client proxy class we just created.

51
00:10:34,318 --> 00:10:42,818
As this would be a lot of repetitive work we won't be doing this in this course you can think of this is a homework assignment if you want to practice your skills and do it yourself.

52
00:10:42,958 --> 00:10:52,778
So to recap distributed tracing is a powerful tool that enables developers and operator and teams to gain deep insights into complex microservices architectures.

53
00:10:53,128 --> 00:11:01,148
We now have all the basic elements set up ourselves that could be used in any real world nastiest microservice application you work on in the future.

54
00:11:01,380 --> 00:11:09,968
Distributed tracing is so beneficial microservices. As it promotes better understanding smoother debugging a more efficient performance optimization.

55
00:11:10,198 --> 00:11:26,168
Making get it an essential part of building and maintaining resilient microservices based systems. For production applications consider using more sophisticated instrumentation tools such as oh open telemetry in combination with jaeger for visualization and analysis.

56
00:11:26,998 --> 00:11:33,218
These tools provide a more comprehensive solution for distributed tracing and can be easily integrated with nastiest applications.

57
00:11:33,988 --> 00:11:40,268
And that's all for this course but thank you again for being here supporting sjs and learning nest with us.

58
00:11:40,348 --> 00:11:49,239
We hope you learned a lot with this course. Make sure to check out the entire catalogue of courses to learn everything else from advanced techniques to nest fundamentals.

